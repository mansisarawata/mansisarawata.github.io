---
layout: page
title: Single View Scene Generation
description: Single-image-to-NeRF predictions
img: assets/img/video_nerf.gif
importance: 1
category: Robotics
# related_publications: einstein1956investigations, einstein1950meaning
---

In this project I am exploring Single View Scene Generation through Individual Object Reconstruction. I delved into advanced techniques for 3D learning employing YOLOvS and SAM for object detection, CubeRCNN for 3D pose estimation, PixelNeRF, and Vision Transformer for single-image-to-NeRF predictions, and iNeRF for 3D object localization, this approach aimed at reconstructing detailed 3D scenes from a single image.

Utilizing Blender-generated scenes and the KITTI dataset, this project validates the methodology's adaptability across diverse scenarios. Beyond technical achievements, the project proposed this approach as an innovative data labeling technique, contributing to annotated datasets for machine learning model training.


In summary, this project showcased dedication to advancing 3D learning, pushing the boundaries of knowledge in computer vision, and contributing innovatively to the field.

In addition to the technical advancements, the project underscored the potential societal impact of our findings. The ability to generate detailed 3D scenes from a single image holds promise for various applications, ranging from virtual reality and augmented reality experiences to autonomous navigation systems. By presenting this approach as a viable data labeling technique, we aim to contribute not only to the academic understanding of 3D learning but also to the practical implementation of advanced computer vision solutions in real-world scenarios. Our commitment to innovation and relevance within the broader technological landscape solidifies this project as a noteworthy exploration at the intersection of cutting-edge research and practical applications.

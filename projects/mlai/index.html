<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>RNN based Visual Odometry | Mansi S. Sarawata</title> <meta name="author" content="Mansi S. Sarawata"> <meta name="description" content="Navigating mobile robots with precision demands accurate vehicle localization, a challenge addressed through vision-based odometry. This study focuses on monocular visual odometry (VO), comparing traditional geometry-based methods with a RNN+CNN model for trajectory estimation. The standard VO pipeline involves feature extraction, camera calibration, and local optimization, requiring prior system knowledge for absolute trajectory recovery. In contrast, the RNN+CNN model infers poses directly, eliminating the need for prior information. The research evaluates both methods using the KITTI Dataset, demonstrating the viability of the end-to-end model over conventional visual odometry systems."> <meta name="keywords" content="academic-website, portfolio-website, mansi-sarawata,mansi,sarawata,airlab,cmu, carnegie, mellon, university"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/11.png?d926b91856498e398fcd888ac80cd296"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mansisarawata.github.io/projects/mlai/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Mansi </span>S. Sarawata</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/files/Mansi_Sarawata_Resume.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">RNN based Visual Odometry</h1> <p class="post-description">Navigating mobile robots with precision demands accurate vehicle localization, a challenge addressed through vision-based odometry. This study focuses on monocular visual odometry (VO), comparing traditional geometry-based methods with a RNN+CNN model for trajectory estimation. The standard VO pipeline involves feature extraction, camera calibration, and local optimization, requiring prior system knowledge for absolute trajectory recovery. In contrast, the RNN+CNN model infers poses directly, eliminating the need for prior information. The research evaluates both methods using the KITTI Dataset, demonstrating the viability of the end-to-end model over conventional visual odometry systems.</p> </header> <article> <p>Accurate vehicle localization is critical for autonomous navigation in mobile robot applications. Various methods, such as wheel odometry, GPS, INS, and visual odometry, address this challenge, each with its limitations. Visual odometry (VO) emerges as a cost-effective alternative, boasting superior accuracy compared to traditional methods. This research specifically delves into monocular VO, aiming to contribute insights and advancements to the field.</p> <p>The study utilizes the KITTI Odometry Benchmark dataset, featuring 22 stereo sequences for training and evaluation. This dataset, provided by the Karlsruhe Institute of Technology, Germany, serves as a comprehensive testing ground. The evaluation involves translational and rotational error computation, providing valuable insights into the performance of the proposed methods.</p> <p>The experimental section presents results from monocular visual odometry and the proposed RNNs for visual odometry on the KITTI dataset. Notably, the research addresses the challenge of aligning localisation results with ground truth due to the lack of absolute scale estimation in most existing monocular VO algorithms.</p> <p>The dataset is split into training and testing sequences, with the model trained on seven path sequences and tested on five. Training involves leveraging NVIDIA CUDA for 100 epochs, incorporating dropout and early stopping techniques to prevent overfitting. A pre-trained FlowNet model is employed to expedite training.</p> <p>Stereo Semi-Global Block Matching (SGBM):</p> <p>The research utilizes OpenCV for stereo depth estimation, employing StereoBM and StereoSGBM methods. Disparity maps and feature matching using SIFT descriptors are visualized, providing insights into tracking vehicle position through sequences.</p> <p>The performance analysis of trained VO models is conducted based on KITTI VO/SLAM evaluation metrics. The CNN+RNN model demonstrates promising results, with the model mapping the roll, pitch, and yaw of the vehicle, showcasing a reduction in errors as epochs progress.</p> <p>Thus the study compares geometry-based visual odometry with an innovative CNN+RNN model, highlighting the latter’s advantage in eliminating the need for prior system knowledge. By leveraging the KITTI dataset, the research contributes valuable insights and advancements to the field of monocular visual odometry, paving the way for more precise and efficient mobile robot navigation.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> <center>© Copyright 2024 Mansi S. Sarawata. <center> Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.</center> </center> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>